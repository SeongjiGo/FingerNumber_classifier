# 진행상황
## 머신러닝 프로젝트: 손 모양을 보고 숫자 인식 다중 분류 모델 만들기
- 구글 코랩을 이용함

1. 2021.11.09
- 데이터 추가
    - 1(yi)부터 10(shi)까지 각각 30장의 사진을 손의 각도, 뒷 배경을 달리하며 촬영함. 아이폰으로 촬영했으며,총 300장의 사진촬영, (3024 * 3024 픽셀), IPEC확장자에서 PNG 확장자로 변환, 총 약 2GB 용량

2. 2021.11.10
- 깃과 연동
    - https://github.com/SeongjiGo/FingerNumber_classifier
    - 깃에 데이터 셋, 코드 파일 PUSH, 깃 연동방법 공부와 적용
- 데이터 경로와 이름, 타겟값 저장. (csv파일 생성)

- transforms 사용자 정의 (사진의 용량을 줄이기 위해 Resize 추가)

3. 2021.11.16
- 코드 주석화, 다른 코드를 참고하여 개발중에 있으며 코드를 이해하며 개발하기 위함.
- 파일이름을 FingerNumber_classifier로 변경

4. 2021.11.18
- 데이터셋 다시 조정, 3024 * 3024 px였던 원본 사진 자체를 10% (302 * 302 px) 만큼 사이즈 축소.(학습 속도가 너무 느림), 원본 파일 모두 삭제
    - 포토스케이프 프로그램 이용
    - transforms의 Resize 제거, 사진의 크기가 모두 동일하고 이미 충분히 작으므로 의미가 없어졌음. 
    - dataSet.zip 업로드
    - 데이터 준비 완료
        - `0. 데이터셋 다운받기`: 여러분이 수집한 데이터의 클래스별로 폴더를 구성하여 데이터셋을 준비합니다.
        - `1. 데이터셋 구성하기`: 저장한 데이터의 정보를 csv 파일로 만듭니다.
        - `2. 데이터셋 불러오기`: csv 파일을 통해 데이터를 불러와서 train, validation, test로 나눠줍니다.
        - `3. 학습 시, 데이터셋을 사용할 수 있도록 만들기`
            - `3-1. Dataset Class`: pytorch가 dataset을 어떻게 읽을지 알려주는 클래스를 만듭니다. (데이터셋 크기와 지정한 인덱스별로 데이터를 리턴해주는 len, getitem 함수가 포함되어 있습니다.)
            - `3-2. Transforms & Augmentation`: 학습을 위해 데이터를 가공합니다.
            - `3-3. Data Loaders`: 배치별로 데이터를 묶어줍니다. Training시, 배치단위별로 데이터가 호출됩니다. 

5. 2021 11.19
- 학습 모듈
- VGG19모델 다운로드 
- train, validation, 학습시키는 코드 추가완료
- 학습 정상 작동
  - 총 15에포크, 1에포크당 학습시간 대략 5분 16초 + 1분 19초 
    - Epoch 1, lr: 0.0000040, train loss: 2.29645, valid loss: 2.25851, Acc: 16.6667.
    - Epoch 2, lr: 0.0000040, train loss: 2.22183, valid loss: 2.12505, Acc: 20.8333.
    - Epoch 3, lr: 0.0000040, train loss: 2.11642, valid loss: 1.97429, Acc: 22.9167.
    - Epoch 4, lr: 0.0000040, train loss: 1.95055, valid loss: 1.87337, Acc: 25.0000.
    - Epoch 5, lr: 0.0000040, train loss: 1.85820, valid loss: 1.73493, Acc: 41.6667.
    - Epoch 6, lr: 0.0000040, train loss: 1.80206, valid loss: 1.61724, Acc: 43.7500.
    - Epoch 7, lr: 0.0000040, train loss: 1.66005, valid loss: 1.52501, Acc: 45.8333.
    - Epoch 8, lr: 0.0000040, train loss: 1.55943, valid loss: 1.40564, Acc: 56.2500.
    - Epoch 9, lr: 0.0000040, train loss: 1.59159, valid loss: 1.32370, Acc: 62.5000.
    - Epoch 10, lr: 0.0000040, train loss: 1.50464, valid loss: 1.25189, Acc: 66.6667.
    - Epoch 11, lr: 0.0000040, train loss: 1.39471, valid loss: 1.18453, Acc: 70.8333.
    - Epoch 12, lr: 0.0000040, train loss: 1.40705, valid loss: 1.12279, Acc: 64.5833.
    - Epoch 13, lr: 0.0000040, train loss: 1.27435, valid loss: 1.07069, Acc: 72.9167.
    - Epoch 14, lr: 0.0000040, train loss: 1.14072, valid loss: 0.97815, Acc: 75.0000.
    - Epoch 15, lr: 0.0000040, train loss: 1.20737, valid loss: 0.93304, Acc: 79.1667.
- 더욱 요구되는 사항
  - conda 인터프리터로 수정 해야 할 것, 수정사항을 반영하려면 다시 1시간 반 동안 인내의 시간이 필요
    - 혹은 학습된 모델을 파일로 저장하여 불러오는 방법도 좋을듯.
  - 에포크를 늘려야 할 듯, 79의 정확도는 좋은 성능이 아님
  - 시각화 할 수 있는 코드를 추가해야 할 것으로 보임
  - 가능하다면 영상을 실시간으로 인식하여 손가락으로 어떤 숫자를 나타내는지 실시간으로 시각화가 최종목표

6. 2021.11.21
- 레포지터리 이름 변경 (ML_project --> FingetNumber_classifier)
- 레포지터리 README 대폭 수정

7. 2021.11.22
- 학습된 모델 저장 코드 추가
- 메뉴생성
  - 1. 새롭게 모델 학습시키기 (사용자가 에포크 지정, 디폴트 == 15)
  - 2. 새로운 사진 분류시켜보기
  - any. 프로그램 종료
- 속도가 오래 걸린 이유가 GPU를 사용하지 않고 CPU를 사용했기 때문인걸 알았음.
  - Pycharm에서 Cuda를 사용하려고 했지만 너무 복잡해서 구글 코랩으로 학습 진행.
  - 1 에포크당 대략 7초밖에 안걸렸음 (기존 5분 40초)
  - 구글 드라이브에 데이터를 업로드하고 코랩에서 마운트를 통해 진행.
- 학습 재진행 (GPU, 150에포크, 에포크당 9초 소요, 대략 23분 소요)
  - Epoch 1, lr: 0.0000040, train loss: 2.32991, valid loss: 2.27254, Acc: 16.6667.
  - Epoch 10, lr: 0.0000040, train loss: 1.36561, valid loss: 1.19962, Acc: 68.7500.
  - Epoch 20, lr: 0.0000040, train loss: 0.95013, valid loss: 0.79968, Acc: 77.0833.
  - Epoch 30, lr: 0.0000040, train loss: 0.72487, valid loss: 0.69045, Acc: 81.2500.
  - Epoch 40, lr: 0.0000040, train loss: 0.56444, valid loss: 0.62446, Acc: 81.2500.
  - Epoch 50, lr: 0.0000040, train loss: 0.52219, valid loss: 0.60561, Acc: 83.3333.
  - ... 중략 ...
  - Epoch 130, lr: 0.0000040, train loss: 0.31015, valid loss: 0.51659, Acc: 89.5833.
  - Epoch 140, lr: 0.0000040, train loss: 0.30637, valid loss: 0.54071, Acc: 83.3333.
  - Epoch 150, lr: 0.0000040, train loss: 0.36674, valid loss: 0.51201, Acc: 87.5000.
- 성능이 그렇게 좋지 않음. 물론 이곳에서 사용되는 정확도는 검증셋에 대한 검사이며 추후 테스트셋으로 검증 진행 예정.
