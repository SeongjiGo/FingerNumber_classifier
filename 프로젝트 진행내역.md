# 진행상황
## 머신러닝 프로젝트: 손 모양을 보고 숫자 인식 다중 분류 모델 만들기
- 구글 코랩을 이용함

1. 2021.11.09
- 데이터 추가
    - 1(yi)부터 10(shi)까지 각각 30장의 사진을 손의 각도, 뒷 배경을 달리하며 촬영함. 아이폰으로 촬영했으며,총 300장의 사진촬영, (3024 * 3024 픽셀), IPEC확장자에서 PNG 확장자로 변환, 총 약 2GB 용량

2. 2021.11.10
- 깃과 연동
    - https://github.com/SeongjiGo/FingerNumber_classifier
    - 깃에 데이터 셋, 코드 파일 PUSH, 깃 연동방법 공부와 적용
- 데이터 경로와 이름, 타겟값 저장. (csv파일 생성)

- transforms 사용자 정의 (사진의 용량을 줄이기 위해 Resize 추가)

3. 2021.11.16
- 코드 주석화, 다른 코드를 참고하여 개발중에 있으며 코드를 이해하며 개발하기 위함.
- 파일이름을 FingerNumber_classifier로 변경

4. 2021.11.18
- 데이터셋 다시 조정, 3024 * 3024 px였던 원본 사진 자체를 10% (302 * 302 px) 만큼 사이즈 축소.(학습 속도가 너무 느림), 원본 파일 모두 삭제
    - 포토스케이프 프로그램 이용
    - ~~transforms의 Resize 제거, 사진의 크기가 모두 동일하고 이미 충분히 작으므로 의미가 없어졌음.~~ 224로 통일
    - dataSet.zip 업로드
    - 데이터 준비 완료
        - `0. 데이터셋 다운받기`: 여러분이 수집한 데이터의 클래스별로 폴더를 구성하여 데이터셋을 준비합니다.
        - `1. 데이터셋 구성하기`: 저장한 데이터의 정보를 csv 파일로 만듭니다.
        - `2. 데이터셋 불러오기`: csv 파일을 통해 데이터를 불러와서 train, validation, test로 나눠줍니다.
        - `3. 학습 시, 데이터셋을 사용할 수 있도록 만들기`
            - `3-1. Dataset Class`: pytorch가 dataset을 어떻게 읽을지 알려주는 클래스를 만듭니다. (데이터셋 크기와 지정한 인덱스별로 데이터를 리턴해주는 len, getitem 함수가 포함되어 있습니다.)
            - `3-2. Transforms & Augmentation`: 학습을 위해 데이터를 가공합니다.
            - `3-3. Data Loaders`: 배치별로 데이터를 묶어줍니다. Training시, 배치단위별로 데이터가 호출됩니다. 

5. 2021 11.19
- 학습 모듈
- VGG19모델 다운로드 
- train, validation, 학습시키는 코드 추가완료
- 학습 정상 작동
  - 총 15에포크, 1에포크당 학습시간 대략 5분 16초 + 1분 19초 
    - Epoch 1, lr: 0.0000040, train loss: 2.29645, valid loss: 2.25851, Acc: 16.6667.
    - Epoch 2, lr: 0.0000040, train loss: 2.22183, valid loss: 2.12505, Acc: 20.8333.
    - Epoch 3, lr: 0.0000040, train loss: 2.11642, valid loss: 1.97429, Acc: 22.9167.
    - Epoch 4, lr: 0.0000040, train loss: 1.95055, valid loss: 1.87337, Acc: 25.0000.
    - Epoch 5, lr: 0.0000040, train loss: 1.85820, valid loss: 1.73493, Acc: 41.6667.
    - Epoch 6, lr: 0.0000040, train loss: 1.80206, valid loss: 1.61724, Acc: 43.7500.
    - Epoch 7, lr: 0.0000040, train loss: 1.66005, valid loss: 1.52501, Acc: 45.8333.
    - Epoch 8, lr: 0.0000040, train loss: 1.55943, valid loss: 1.40564, Acc: 56.2500.
    - Epoch 9, lr: 0.0000040, train loss: 1.59159, valid loss: 1.32370, Acc: 62.5000.
    - Epoch 10, lr: 0.0000040, train loss: 1.50464, valid loss: 1.25189, Acc: 66.6667.
    - Epoch 11, lr: 0.0000040, train loss: 1.39471, valid loss: 1.18453, Acc: 70.8333.
    - Epoch 12, lr: 0.0000040, train loss: 1.40705, valid loss: 1.12279, Acc: 64.5833.
    - Epoch 13, lr: 0.0000040, train loss: 1.27435, valid loss: 1.07069, Acc: 72.9167.
    - Epoch 14, lr: 0.0000040, train loss: 1.14072, valid loss: 0.97815, Acc: 75.0000.
    - Epoch 15, lr: 0.0000040, train loss: 1.20737, valid loss: 0.93304, Acc: 79.1667.
- 더욱 요구되는 사항
  - conda 인터프리터로 수정 해야 할 것, 수정사항을 반영하려면 다시 1시간 반 동안 인내의 시간이 필요
    - 혹은 학습된 모델을 파일로 저장하여 불러오는 방법도 좋을듯.
  - 에포크를 늘려야 할 듯, 79의 정확도는 좋은 성능이 아님
  - 시각화 할 수 있는 코드를 추가해야 할 것으로 보임
  - 가능하다면 영상을 실시간으로 인식하여 손가락으로 어떤 숫자를 나타내는지 실시간으로 시각화가 최종목표

6. 2021.11.21
- 레포지터리 이름 변경 (ML_project --> FingetNumber_classifier)
- 레포지터리 README 대폭 수정

7. 2021.11.22
- 학습된 모델 저장 코드 추가
- 메뉴생성
  - 1. 새롭게 모델 학습시키기 (사용자가 에포크 지정, 디폴트 == 15)
  - 2. 새로운 사진 분류시켜보기 (미구현)
  - any. 프로그램 종료
- 속도가 오래 걸린 이유가 GPU를 사용하지 않고 CPU를 사용했기 때문인걸 알았음.
  - Pycharm에서 Cuda를 사용하려고 했지만 너무 복잡해서 구글 코랩으로 학습 진행.
  - 1 에포크당 대략 7초밖에 안걸렸음 (기존 5분 40초)
  - 구글 드라이브에 데이터를 업로드하고 코랩에서 마운트를 통해 진행.
- 학습 재진행 (GPU, 150에포크, 에포크당 9초 소요, 대략 23분 소요)
  - Epoch 1, lr: 0.0000040, train loss: 2.32991, valid loss: 2.27254, Acc: 16.6667.
  - Epoch 10, lr: 0.0000040, train loss: 1.36561, valid loss: 1.19962, Acc: 68.7500.
  - Epoch 20, lr: 0.0000040, train loss: 0.95013, valid loss: 0.79968, Acc: 77.0833.
  - Epoch 30, lr: 0.0000040, train loss: 0.72487, valid loss: 0.69045, Acc: 81.2500.
  - Epoch 40, lr: 0.0000040, train loss: 0.56444, valid loss: 0.62446, Acc: 81.2500.
  - Epoch 50, lr: 0.0000040, train loss: 0.52219, valid loss: 0.60561, Acc: 83.3333.
  - ... 중략 ...
  - Epoch 130, lr: 0.0000040, train loss: 0.31015, valid loss: 0.51659, Acc: 89.5833.
  - Epoch 140, lr: 0.0000040, train loss: 0.30637, valid loss: 0.54071, Acc: 83.3333.
  - Epoch 150, lr: 0.0000040, train loss: 0.36674, valid loss: 0.51201, Acc: 87.5000.
- 성능이 그렇게 좋지 않음. 물론 이곳에서 사용되는 정확도는 검증셋에 대한 검사이며 추후 테스트셋으로 검증 진행 예정.
- 테스트 셋으로 최종 정확도를 측정하는 코드 추가
- v 0.2 업데이트 일시

8. 2021.11.23
- 성능 향상을 위해 배치사이즈 1로 변경.
    - [기존 배치사이즈: 4] ~~Epoch 15, lr: 0.0000040, train loss: 1.20737, valid loss: 0.93304, Acc: 79.1667.~~
    - [변경 배치사이즈: 1] Epoch 15, lr: 0.0000040, train loss: 0.95048, valid loss: 0.76432, Acc: 81.2500. loss율이 낮아짐을 알 수 있음.
    - 1에포크당 소요시간 7초 -> 11초 
- 성능이 그리 좋지가 않음, 데이터 혹은 모델을 바꾸던 해야할듯 함. 
    - 검증셋에 대한 오차율이 0.57xx 이하로 떨어지지 않음.
    - 정확도 최대 83.333% (48장 중 8개 틀림), 배치를 늘렸더니 오히려 학습이 잘 안되는 걸 보니 데이터에 노이즈가 많이 있어서 그런듯
        - 180도 손을 돌려가면서 찍었는데, 카메라와 손 날이 수직이 되는 순간이 있었고 이러한 데이터들이 방해가 되는 것으로 추정
    - <img width="770" alt="image" src="https://user-images.githubusercontent.com/46768743/142973490-b51548e9-d964-4556-b438-a52d4d7e56f5.png">
    - 최종 테스트셋으로 검증해본 결과 88%의 정확도, (60개를 테스트한 결과 53개 정답)
    - 조심스럽게 예측컨데, 틀린 7개는 거의 대부분 손가락이 수직으로 되어있을 때일 것으로 예상.
    - 어쩌면 성능이 낮은게 아니라 질이 매우 안좋은 노이즈에 대해 예측을 실패한 것이므로 정상적인 사진에 대해서는 좋을수도..?

9. 2021.11.26
- split과정에서 random_state가 지정이 되어있던 것 제거
- matplotlib을 이용하여 각 에포크당 loss율, 정확도 시각화 코드 추가
- 새로운 사진에 대해 분류해보는 코드 일부 추가.

10. 2021.11.28
- learning rate를 inverse sqrt로 변경 ( init_lr / epoch ** 0.5 ), 즉 점차 LR을 감소시키는 형태. 
    - 초기 값 ```4e-6``` 시도 --> 학습속도 느려짐.
    - 초기 값 ```4e-5``` 시도 --> 학습속도는 비슷하나 최종 성능이 향상된 것으로 보임.
    - LR의 대략적 변화:
        1) Epoch 1, lr: 0.0000400 
        2) Epoch 2, lr: 0.0000283
        3) Epoch 3, lr: 0.0000231
        4) Epoch 4, lr: 0.0000200
        5) Epoch 5, lr: 0.0000179
        6) .......
        7) Epoch 30, lr: 0.0000073
        - 위의 8번 (2021.11.23) 항목을 보자. 오차율이 0.57xx아래로 떨어지지 않는다고 하였는데, LR을 바꾸니 검증셋 기준 0.23까지 Loss가 감소했다!!
        - Epoch 1, lr: 0.0000400, train loss: 2.28205, valid loss: 1.42319, Acc: 54.1667.
        - Epoch 5, lr: 0.0000179, train loss: 1.07706, valid loss: 0.54787, Acc: 85.4167.
        - Epoch 10, lr: 0.0000126, train loss: 0.63708, valid loss: 0.35329, Acc: 85.4167.
        - Epoch 15, lr: 0.0000103, train loss: 0.64687, valid loss: 0.32597, Acc: 91.6667.
        - Epoch 20, lr: 0.0000089, train loss: 0.60066, valid loss: 0.28372, Acc: 89.5833.
        - Epoch 25, lr: 0.0000080, train loss: 0.61987, valid loss: 0.25882, Acc: 91.6667.
        - Epoch 30, lr: 0.0000073, train loss: 0.49362, valid loss: 0.27402, Acc: 83.3333.

11. 2021.12.01
- 필요없는 코드 최소화, 코드 짧아짐
- 메뉴 시스템 제거, 쉘을 통하여 진행
- train셋과 test셋 비율을 8:2에서 9:1로 바꿈. 데이터 수가 너무 적기 때문임.
- V 0.3 업데이트 새로운 사진에 대해 예측하는 코드 완성
    - 성능이 너무 안좋음.. 지인에게 사진을 찍어 4개를 받았는게 1개만 예측 성공

12. 2021.12.02
- dataSet의 사진에 대해서는 매우 훌륭한 분류 능력을 가졌지만, 새로운 환경에서 찍은것에 대해는 엉망
- 일반화가 잘 안된 것으로 보임, 데이터 품질에 대해 문제가 있는것으로 파악
- 데이터 수를 더 늘려야 할 것으로 보임...
  
13. 2021.12.04
- 모델을 저장할 때 최종 학습이 끝날떄의 모델을 저장하는게 아니라, 로스가 최소인 순간을 저장
