{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FingerNumber_classifier_V0.3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1F4QkB5xhrFAS0oO7g1WOnT-mfwcZPv5L",
      "authorship_tag": "ABX9TyNf1xw6ZueYBFuS/+MtnpNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongjiGo/FingerNumber_classifier/blob/master/FingerNumber_classifier_V0_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "q8xXWfV86dgA",
        "outputId": "ca0629b1-cd33-4d0f-ff48-ec3ab9268693"
      },
      "source": [
        "print(\"모델을 새로 학습합니다.\")\n",
        "epochNum = int(input(\"원하는 에포크 수를 입력해주세요: \"))\n",
        "print(\"batch_size : 1 기준 1 epoch당 15초 정도 소요됩니다.\")\n",
        "print(f\"{epochNum}으로 에포크를 설정하였습니다.\")\n",
        "print(\"모델 학습을 시작합니다.\")\n",
        "\n",
        "# 데이터 셋 구성하기, 경로를 파악한 후\n",
        "# 클래스 이름(name), 클래스(class), 그리고 학습을 위한 클래스를 숫자로 나타낸 타겟(target)을 csv파일에 저장\n",
        "import os\n",
        "from glob import glob # 인자로 받은 패턴과 이름이 일치하는 모든 파일과 디렉터리의 리스트 반환\n",
        "import pandas as pd\n",
        "\n",
        "file_path = './drive/MyDrive/FingerNumber_classifier_project/dataSet/*/*.png' # 데이터의 경로 저장\n",
        "file_list = glob(file_path)\n",
        "\n",
        "data_dict = {'image_name':[], 'class':[], 'target':[], 'file_path':[]}\n",
        "# 학습에 사용하기 위한 넘버링(?)\n",
        "target_dict = {'yi_1': 0, 'er_2': 1, 'san_3': 2, 'si_4':3, 'wu_5':4, 'liu_6':5, 'qi_7':6, 'ba_8':7, 'jiu_9':8, 'shi_10': 9}\n",
        "\n",
        "for path in file_list:\n",
        "    data_dict['file_path'].append(path) # file_path 항목에 파일 경로 저장\n",
        "\n",
        "    path_list = path.split(os.path.sep) # os별 파일 경로 구분 문자로 split\n",
        "\n",
        "    data_dict['image_name'].append(path_list[-1]) # 이미지 이름 저장\n",
        "    data_dict['class'].append(path_list[-2]) # 어떤 클래스인지 저장\n",
        "    data_dict['target'].append(target_dict[path_list[-2]]) # 그 클래스의 번호 저장\n",
        "\n",
        "train_df = pd.DataFrame(data_dict) # 데이터 프레임 화\n",
        "train_df.to_csv(\"./drive/MyDrive/FingerNumber_classifier_project/train.csv\", mode='w') # csv파일로 생성\n",
        "print('csv파일 생성 완료!')\n",
        "\n",
        "from sklearn.model_selection import train_test_split # 스플릿 모듈\n",
        "def get_df():\n",
        "    # csv 파일 읽어서 DataFrame으로 저장\n",
        "    df = pd.read_csv(\"./drive/MyDrive/FingerNumber_classifier_project/train.csv\") # csv로 불러와서 데이터 저장\n",
        "    print('csv 파일 DataFrame으로 저장 완료!')\n",
        "\n",
        "    # 데이터셋을 train, val, test로 나누기\n",
        "    df_train, df_test = train_test_split(df, test_size=0.1)\n",
        "    df_train, df_val = train_test_split(df_train, test_size=0.2)\n",
        "    print('훈련셋, 검증셋, 테스트셋 분할 완료!')\n",
        "    return df_train, df_val, df_test\n",
        "\n",
        "# 데이터셋 읽어오기\n",
        "df_train, df_val, df_test = get_df()\n",
        "print(f'훈련셋 개수:{len(df_train)}, 검증셋 개수:{len(df_val)}, 테스트셋 개수: {len(df_test)}') # 192, 48, 60\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# 학습시, 데이터셋을 사용할 수 있도록 만들기\n",
        "class Classification_Dataset(Dataset):\n",
        "    def __init__(self, csv, mode, transform=None):\n",
        "        self.csv = csv.reset_index(drop=True) # random으로 섞인 데이터의 인덱스를 reset 시켜서 다시 부여한다.\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.csv.shape[0] # csv 파일의 행 개수 == 데이터 개수\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.csv.iloc[index] # 주어진 index에 대한 데이터 뽑아오기\n",
        "        image = Image.open(row.file_path).convert('RGB') # 파일 경로로 부터 이미지를 읽고 rgb로 변환하기\n",
        "        target = torch.tensor(self.csv.iloc[index].target).long()\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image) # 이미지에 transform 적용하기\n",
        "\n",
        "        return image, target # 이미지와 target return하기기\n",
        "\n",
        "\n",
        "# normalize를 위해 rgb 채널의 mean, std 값 구하기\n",
        "\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "dataset_train = Classification_Dataset(df_train, 'train', transform=transforms.ToTensor())\n",
        "\n",
        "# 데이터(shape:torch.Size([3, 381, 343])) rgb에 대한 mean, std 구하기\n",
        "rgb_mean = [np.mean(x.numpy(), axis=(1, 2)) for x, _ in dataset_train]\n",
        "rgb_std = [np.std(x.numpy(), axis=(1, 2)) for x, _ in dataset_train]\n",
        "\n",
        "# 각 데이터 채널별로 mean, std 나타내기\n",
        "c_mean = []\n",
        "c_std = []\n",
        "for i in range(3):\n",
        "    c_mean.append(np.mean([m[i] for m in rgb_mean]))\n",
        "    c_std.append(np.std([s[i] for s in rgb_std]))\n",
        "\n",
        "print('rgb의 mean, std값 계산 완료!')\n",
        "# 사용자 모델 트랜스폼\n",
        "def get_transforms(image_size):\n",
        "    transforms_train = transforms.Compose([\n",
        "        transforms.RandomRotation(30), # 이미지의 다양화를 위해 랜덤으로 +- 30도 가량 회전\n",
        "        transforms.RandomResizedCrop(image_size), # 이미지 사이즈 축소\n",
        "        transforms.RandomHorizontalFlip(), # 이미지를 랜덤으로 수평하게 뒤집음.\n",
        "        transforms.ToTensor(), # 데이터 타입을 텐서로 변경\n",
        "        transforms.Normalize(c_mean, c_std) ]) # 정규화\n",
        "\n",
        "    transforms_val = transforms.Compose([transforms.Resize(image_size + 30), \n",
        "                                            transforms.CenterCrop(image_size), # 이미지의 가운데 부분을 인자값으로 자름\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize(c_mean, c_std)])\n",
        "    \n",
        "    transforms_test = transforms.Compose([transforms.Resize(image_size),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize(c_mean, c_std)]) # 정규화\n",
        "\n",
        "    return transforms_train, transforms_val, transforms_test\n",
        "\n",
        "# 모델 트랜스폼 가져오기\n",
        "transforms_train, transforms_val, transforms_test = get_transforms(224)\n",
        "print(\"모델 트랜스폼 불러오기 완료!\")\n",
        "\n",
        "# dataset class 객체 만들기\n",
        "dataset_train = Classification_Dataset(df_train, 'train', transform=transforms_train)\n",
        "dataset_val = Classification_Dataset(df_val, 'valid', transform=transforms_val)\n",
        "dataset_test = Classification_Dataset(df_test, 'test', transform=transforms_test) \n",
        "print('dataset class 객체 생성 완료!')\n",
        "\n",
        "# DataLoader는 Classification_Dataset으로 받아온 데이터(이미지, target)를 batch로 묶어 return합니다.\n",
        "from torch.utils.data.sampler import RandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=1, sampler=RandomSampler(dataset_train), num_workers=0)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset_val, batch_size=1, num_workers=0)\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1, num_workers=0)\n",
        "print('데이터 로더 완료!')\n",
        "#### 데이터 준비 파트는 마무리가 되었습니다. 큰 틀을 살펴보면서 정리해보도록 하겠습니다.\n",
        "# 0. 데이터셋 다운받기`: 여러분이 수집한 데이터의 클래스별로 폴더를 구성하여 데이터셋을 준비합니다.\n",
        "# 1. 데이터셋 구성하기`: 저장한 데이터의 정보를 csv 파일로 만듭니다.\n",
        "# 2. 데이터셋 불러오기`: csv 파일을 통해 데이터를 불러와서 train, validation, test로 나눠줍니다.\n",
        "# 3. 학습 시, 데이터셋을 사용할 수 있도록 만들기\n",
        "#     3-1. Dataset Class`: pytorch가 dataset을 어떻게 읽을지 알려주는 클래스를 만듭니다. (데이터셋 크기와 지정한 인덱스별로 데이터를 리턴해주는 len, getitem 함수가 포함되어 있습니다.)\n",
        "#     3-2. Transforms & Augmentation`: 학습을 위해 데이터를 가공합니다.\n",
        "#     3-3. Data Loaders`: 배치별로 데이터를 묶어줍니다. Training시, 배치단위별로 데이터가 호출됩니다.\n",
        "\n",
        "# Model 설정\n",
        "from torchvision import models\n",
        "from collections import OrderedDict\n",
        "import torch.nn as nn\n",
        "\n",
        "model = models.vgg19(pretrained=True)\n",
        "# # Backprop을 수행하지 않도록 parameter들을 동결시키기\n",
        "# # 재학습을 위해, 모든 parameters의 gradient를 꺼놓기\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "    ('fc1', nn.Linear(25088, 500)),\n",
        "    ('relu', nn.ReLU()),\n",
        "    ('fc2', nn.Linear(500, 10))\n",
        "]))\n",
        "\n",
        "model.classifier = classifier\n",
        "print('VGG19 모델 셋팅 완료')\n",
        "\n",
        "# Training\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm # tqdm은 작업의 진행률을 시각적으로 표시해준다.\n",
        "\n",
        "# train\n",
        "def train_epoch(model, loader, device, criterion, optimizer):\n",
        "    model.train() # 모델 train 모드로 바꾸기\n",
        "    train_loss = []\n",
        "    bar = tqdm(loader)\n",
        "\n",
        "    for i, (data, target) in enumerate(bar):\n",
        "        optimizer.zero_grad() # 최적화된 모든 변수 초기화\n",
        "\n",
        "        data, target = data.to(device), target.to(device) # 지정한 device로 데이터 옮기기\n",
        "        logits = model(data) # 1. forward pass\n",
        "\n",
        "        loss = criterion(logits, target) # 2. loss계산\n",
        "        loss.backward() # 3. backward pass\n",
        "        optimizer.step() # 4. gradient descent(파라미터 업데이트)\n",
        "\n",
        "        loss_np = loss.detach().cpu().numpy() # loss값 가져오기 위해 gpu에 있던 데이터 모두 cpu로 옮기기\n",
        "        train_loss.append(loss_np)\n",
        "        bar.set_description('loss: %.5f' % (loss_np))\n",
        "\n",
        "    train_loss = np.mean(train_loss) # 한 epoch당 train loss의 평균 구하기\n",
        "    return train_loss\n",
        "\n",
        "# Validation\n",
        "def val_epoch(model, loader, device, criterion):\n",
        "    model.eval() # 모델 evaluate 모드로 바꾸기\n",
        "    val_loss = []\n",
        "    LOGITS = []\n",
        "    PROBS = []\n",
        "    TARGETS = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (data, target) in tqdm(loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            logits = model(data)    # 1. forward pass\n",
        "            probs = logits.softmax(1)\n",
        "\n",
        "            LOGITS.append(logits.detach().cpu())\n",
        "            PROBS.append(probs.detach().cpu())\n",
        "            TARGETS.append(target.detach().cpu())\n",
        "\n",
        "            loss = criterion(logits, target)    # 2. loss 계산\n",
        "            val_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    val_loss = np.mean(val_loss)\n",
        "    LOGITS = torch.cat(LOGITS).numpy()\n",
        "    PROBS = torch.cat(PROBS).numpy()\n",
        "    TARGETS = torch.cat(TARGETS).numpy()\n",
        "\n",
        "    # accuracy: 정확도\n",
        "    acc = (PROBS.argmax(1) == TARGETS).mean() * 100.\n",
        "\n",
        "    return val_loss, acc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# 학습시키기\n",
        "def run(model = model, init_lr = 0.1, n_epochs = 15):\n",
        "    # gpu 사용\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"현재 장치: {device}\")\n",
        "    # model을 지정한 장치로 옮기기\n",
        "    model = model.to(device)\n",
        "\n",
        "    # loss function 지정\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # optimizer로 adam 사용\n",
        "    optimizer = optim.Adam(model.parameters(), lr = init_lr)\n",
        "\n",
        "    \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    accurates = []\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        print(time.ctime(), f'Epoch {epoch}')\n",
        "        optimizer.param_groups[0][\"lr\"] = init_lr / (epoch ** 0.5)\n",
        "        train_loss = train_epoch(model, train_loader, device, criterion, optimizer) # train\n",
        "        val_loss, acc = val_epoch(model, valid_loader, device, criterion) # validation\n",
        "\n",
        "        content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {(val_loss):.5f}, Acc: {(acc):.4f}.'\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        accurates.append(acc)\n",
        "        print(content)\n",
        "    \n",
        "    torch.save(model, '/content/drive/MyDrive/FingerNumber_classifier_project/best_model.pth')\n",
        "    return train_losses, val_losses, accurates\n",
        "    \n",
        "\n",
        "train_losses, val_losses, accurates = run(model, init_lr=4e-5, n_epochs=epochNum)\n",
        "print(\"가장 좋은 성능의 모델 저장 완료!\")\n",
        "print(\"학습 종료\");\n",
        "\n",
        "plt.plot(range(1, epochNum+1), train_losses, 'r', label=\"train_loss\")\n",
        "plt.plot(range(1, epochNum+1), val_losses, 'g', label=\"valid_loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(1, epochNum+1), accurates, 'b', label=\"accurate\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accurate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n테스트셋으로 최종 정확도를 계산합니다.\")\n",
        "\n",
        "def run_test(model = model, n_epochs = 1):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # loss function 지정\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # optimizer로 adam 사용\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        test_loss, acc = val_epoch(model, test_loader, device, criterion) # val_epoch지만 loader에 test_loader을 기입\n",
        "        print(f'\\t새로운 이미지에 대한 정확도: {acc}.')\n",
        "\n",
        "run_test(model)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== FingerNumber_Classifier ==========\n",
            "[0] 모델 새로 학습하기 (첫 실행은 반드시 새로 학습해야합니다.)\n",
            "[1] 학습된 모델로 새로운 사진 분류해보기\n",
            "[any] 종료\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-11437ac43978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmenu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"숫자를 입력해주세요: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmenu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiMxBx15BjtA",
        "outputId": "0f345ff9-29fb-4c57-c707-08c58a4657ad"
      },
      "source": [
        "# 새로운 이미지 예측해보기 \n",
        "model = torch.load('/content/drive/MyDrive/FingerNumber_classifier_project/best_model.pth')\n",
        "model.eval()\n",
        "\n",
        "print(\"\\n아직 구현실력이 부족하여 구글드라이브의 특정 위치에 사진을 업로드 하고 마운트하여 진행합니다.\")\n",
        "print(\"분류할 사진 파일을 /content/drive/MyDrive/FingerNumber_classifier_project 경로에 newImage.png 의 이름으로 추가해주시기 바랍니다.\")\n",
        "input(\"업로드가 완료되면 엔터를 입력해주세요.\")\n",
        "\n",
        "newImage = Image.open(\"/content/drive/MyDrive/FingerNumber_classifier_project/newImage.png\").convert('RGB')\n",
        "print(\"이미지를 성공적으로 불러왔습니다!\")\n",
        "newImage = transforms_test(newImage)\n",
        "print(\"새로운 이미지 transform 적용 완료\")\n",
        "print(f'newImage type: {type(newImage)}, newImage shape: {newImage.shape}')\n",
        "\n",
        "newImage = newImage.view(1, 3, 224, 224)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "newImage = newImage.to(device)\n",
        "model = model.to(device)\n",
        "\n",
        "print(f'newImage type: {type(newImage)}, newImage shape: {newImage.shape}')\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(newImage) # 1. forward pass\n",
        "    probs = logits.softmax(1)  \n",
        "    probs = probs.detach().cpu()\n",
        "print(probs.argmax(1) + 1)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "아직 구현실력이 부족하여 구글드라이브의 특정 위치에 사진을 업로드 하고 마운트하여 진행합니다.\n",
            "분류할 사진 파일을 /content/drive/MyDrive/FingerNumber_classifier_project 경로에 newImage.png 의 이름으로 추가해주시기 바랍니다.\n",
            "업로드가 완료되면 엔터를 입력해주세요.\n",
            "이미지를 성공적으로 불러왔습니다!\n",
            "새로운 이미지 transform 적용 완료\n",
            "newImage type: <class 'torch.Tensor'>, newImage shape: torch.Size([3, 224, 224])\n",
            "newImage type: <class 'torch.Tensor'>, newImage shape: torch.Size([1, 3, 224, 224])\n",
            "tensor([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLDtq9yR2NVq",
        "outputId": "60791906-271e-4ecb-837f-d8ae3c16a482"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}