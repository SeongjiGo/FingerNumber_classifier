{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FingerNumber_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CiGp008K7eMHjk3Q-LtShkxNTxxbKZoX",
      "authorship_tag": "ABX9TyPajX6HZuW7SJ+1zCdSdQT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongjiGo/FingerNumber_classifier/blob/master/FingerNumber_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8xXWfV86dgA",
        "outputId": "62acb575-b6a9-4790-b579-4ff7abe6f357"
      },
      "source": [
        "print(\"FingerNumber_Classifier\")\n",
        "print(\"[0] 모델 새로 학습하기\")\n",
        "print(\"[1] 학습된 모델로 새로운 사진 분류해보기\")\n",
        "print(\"[any] 종료\")\n",
        "\n",
        "\n",
        "menu = input(\"숫자를 입력해주세요: \")\n",
        "\n",
        "if menu == '0':\n",
        "    print(\"모델을 새로 학습합니다.\")\n",
        "    print(\"15 에포크 기준 정확도는 약 79%입니다.\")\n",
        "    epochNum = int(input(\"원하는 에포크 수를 입력해주세요: \"))\n",
        "    print(f\"{epochNum}으로 에포크를 설정하였습니다.\")\n",
        "    print(\"모델 학습을 시작합니다.\")\n",
        "\n",
        "elif menu == '1':\n",
        "    print(\"분류를 진행합니다.\")\n",
        "    file_path = input(\"파일의 [절대경로]를 입력해주세요: \")\n",
        "\n",
        "else:\n",
        "    print('프로그램을 종료합니다.')\n",
        "\n",
        "if menu == '0':\n",
        "    # 데이터 셋 구성하기, 경로를 파악한 후\n",
        "    # 클래스 이름(name), 클래스(class), 그리고 학습을 위한 클래스를 숫자로 나타낸 타겟(target)을 csv파일에 저장\n",
        "    import os\n",
        "    from glob import glob # 인자로 받은 패턴과 이름이 일치하는 모든 파일과 디렉터리의 리스트 반환\n",
        "    import pandas as pd\n",
        "\n",
        "    file_path = './drive/MyDrive/FingerNumber_classifier_project/dataSet/*/*.png' # 데이터의 경로 저장\n",
        "    file_list = glob(file_path)\n",
        "\n",
        "    data_dict = {'image_name':[], 'class':[], 'target':[], 'file_path':[]}\n",
        "    # 학습에 사용하기 위한 넘버링(?)\n",
        "    target_dict = {'yi_1': 0, 'er_2': 1, 'san_3': 2, 'si_4':3, 'wu_5':4, 'liu_6':5, 'qi_7':6, 'ba_8':7, 'jiu_9':8, 'shi_10': 9}\n",
        "\n",
        "    for path in file_list:\n",
        "        data_dict['file_path'].append(path) # file_path 항목에 파일 경로 저장\n",
        "\n",
        "        path_list = path.split(os.path.sep) # os별 파일 경로 구분 문자로 split\n",
        "\n",
        "        data_dict['image_name'].append(path_list[-1]) # 이미지 이름 저장\n",
        "        data_dict['class'].append(path_list[-2]) # 어떤 클래스인지 저장\n",
        "        data_dict['target'].append(target_dict[path_list[-2]]) # 그 클래스의 번호 저장\n",
        "\n",
        "    train_df = pd.DataFrame(data_dict) # 데이터 프레임 화\n",
        "    train_df.to_csv(\"./drive/MyDrive/FingerNumber_classifier_project/train.csv\", mode='w') # csv파일로 생성\n",
        "    print('csv파일 생성 완료!')\n",
        "\n",
        "    from sklearn.model_selection import train_test_split # 스플릿 모듈\n",
        "    def get_df():\n",
        "        # csv 파일 읽어서 DataFrame으로 저장\n",
        "        df = pd.read_csv(\"./drive/MyDrive/FingerNumber_classifier_project/train.csv\") # csv로 불러와서 데이터 저장\n",
        "        print('csv 파일 DataFrame으로 저장 완료!')\n",
        "\n",
        "        # 데이터셋을 train, val, test로 나누기\n",
        "        df_train, df_test = train_test_split(df, test_size=0.2)\n",
        "        df_train, df_val = train_test_split(df_train, test_size=0.2)\n",
        "        print('훈련셋, 검증셋, 테스트셋 분할 완료!')\n",
        "        return df_train, df_val, df_test\n",
        "\n",
        "    # 데이터셋 읽어오기\n",
        "    df_train, df_val, df_test = get_df()\n",
        "    print(f'훈련셋 개수:{len(df_train)}, 검증셋 개수:{len(df_val)}, 테스트셋 개수: {len(df_test)}') # 192, 48, 60\n",
        "\n",
        "    import torch\n",
        "    from torch.utils.data import Dataset\n",
        "    from PIL import Image\n",
        "\n",
        "    # 학습시, 데이터셋을 사용할 수 있도록 만들기\n",
        "    class Classification_Dataset(Dataset):\n",
        "        def __init__(self, csv, mode, transform=None):\n",
        "            self.csv = csv.reset_index(drop=True) # random으로 섞인 데이터의 인덱스를 reset 시켜서 다시 부여한다.\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return self.csv.shape[0] # csv 파일의 행 개수 == 데이터 개수\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            row = self.csv.iloc[index] # 주어진 index에 대한 데이터 뽑아오기\n",
        "            image = Image.open(row.file_path).convert('RGB') # 파일 경로로 부터 이미지를 읽고 rgb로 변환하기\n",
        "            target = torch.tensor(self.csv.iloc[index].target).long()\n",
        "\n",
        "            if self.transform:\n",
        "                image = self.transform(image) # 이미지에 transform 적용하기\n",
        "\n",
        "            return image, target # 이미지와 target return하기기\n",
        "\n",
        "\n",
        "    # normalize를 위해 rgb 채널의 mean, std 값 구하기\n",
        "\n",
        "    import numpy as np\n",
        "    from torchvision import transforms\n",
        "    dataset_train = Classification_Dataset(df_train, 'train', transform=transforms.ToTensor())\n",
        "\n",
        "    # 데이터(shape:torch.Size([3, 381, 343])) rgb에 대한 mean, std 구하기\n",
        "    rgb_mean = [np.mean(x.numpy(), axis=(1, 2)) for x, _ in dataset_train]\n",
        "    rgb_std = [np.std(x.numpy(), axis=(1, 2)) for x, _ in dataset_train]\n",
        "\n",
        "    # 각 데이터 채널별로 mean, std 나타내기\n",
        "    c_mean = []\n",
        "    c_std = []\n",
        "    for i in range(3):\n",
        "        c_mean.append(np.mean([m[i] for m in rgb_mean]))\n",
        "        c_std.append(np.std([s[i] for s in rgb_std]))\n",
        "\n",
        "    print('rgb의 mean, std값 계산 완료!')\n",
        "    # 사용자 모델 트랜스폼\n",
        "    def get_transforms(image_size):\n",
        "        transforms_train = transforms.Compose([\n",
        "            transforms.RandomRotation(30), # 이미지의 다양화를 위해 랜덤으로 +- 30도 가량 회전\n",
        "            transforms.RandomResizedCrop(image_size), # 이미지 사이즈 축소\n",
        "            transforms.RandomHorizontalFlip(), # 이미지를 랜덤으로 수평하게 뒤집음.\n",
        "            transforms.ToTensor(), # 데이터 타입을 텐서로 변경\n",
        "            transforms.Normalize(c_mean, c_std) ]) # 정규화\n",
        "\n",
        "        transforms_val = transforms.Compose([transforms.Resize(image_size + 30), # 이미지 사이즈 축소\n",
        "                                             transforms.CenterCrop(image_size), # 이미지의 가운데 부분을 인자값으로 자름\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize(c_mean, c_std)])\n",
        "        \n",
        "        transforms_test = transforms.Compose([transforms.Resize(image_size),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize(c_mean, c_std)]) # 정규화\n",
        "\n",
        "        return transforms_train, transforms_val, transforms_test\n",
        "\n",
        "    # 모델 트랜스폼 가져오기\n",
        "    transforms_train, transforms_val, transforms_test = get_transforms(224)\n",
        "    print(\"모델 트랜스폼 불러오기 완료!\")\n",
        "\n",
        "    # dataset class 객체 만들기\n",
        "    dataset_train = Classification_Dataset(df_train, 'train', transform=transforms_train)\n",
        "    dataset_val = Classification_Dataset(df_val, 'valid', transform=transforms_val)\n",
        "    dataset_test = Classification_Dataset(df_test, 'test', transform=transforms_test) \n",
        "    print('dataset class 객체 생성 완료!')\n",
        "\n",
        "    # DataLoader는 Classification_Dataset으로 받아온 데이터(이미지, target)를 batch로 묶어 return합니다.\n",
        "    from torch.utils.data.sampler import RandomSampler\n",
        "    from torch.utils.data import DataLoader\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=1, sampler=RandomSampler(dataset_train), num_workers=0)\n",
        "    valid_loader = torch.utils.data.DataLoader(dataset_val, batch_size=1, num_workers=0)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1, num_workers=0)\n",
        "    print('데이터 로더 완료!')\n",
        "    #### 데이터 준비 파트는 마무리가 되었습니다. 큰 틀을 살펴보면서 정리해보도록 하겠습니다.\n",
        "    # 0. 데이터셋 다운받기`: 여러분이 수집한 데이터의 클래스별로 폴더를 구성하여 데이터셋을 준비합니다.\n",
        "    # 1. 데이터셋 구성하기`: 저장한 데이터의 정보를 csv 파일로 만듭니다.\n",
        "    # 2. 데이터셋 불러오기`: csv 파일을 통해 데이터를 불러와서 train, validation, test로 나눠줍니다.\n",
        "    # 3. 학습 시, 데이터셋을 사용할 수 있도록 만들기\n",
        "    #     3-1. Dataset Class`: pytorch가 dataset을 어떻게 읽을지 알려주는 클래스를 만듭니다. (데이터셋 크기와 지정한 인덱스별로 데이터를 리턴해주는 len, getitem 함수가 포함되어 있습니다.)\n",
        "    #     3-2. Transforms & Augmentation`: 학습을 위해 데이터를 가공합니다.\n",
        "    #     3-3. Data Loaders`: 배치별로 데이터를 묶어줍니다. Training시, 배치단위별로 데이터가 호출됩니다.\n",
        "\n",
        "    # Model 설정\n",
        "    from torchvision import models\n",
        "    from collections import OrderedDict\n",
        "    import torch.nn as nn\n",
        "\n",
        "    model = models.vgg19(pretrained=True)\n",
        "    # # Backprop을 수행하지 않도록 parameter들을 동결시키기\n",
        "    # # 재학습을 위해, 모든 parameters의 gradient를 꺼놓기\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 마지막 layer를 과제에 맞게 수정하기\n",
        "    classifier = nn.Sequential(OrderedDict([\n",
        "        ('fc1', nn.Linear(25088, 500)),\n",
        "        ('relu', nn.ReLU()),\n",
        "        ('fc2', nn.Linear(500, 10))\n",
        "    ]))\n",
        "\n",
        "    model.classifier = classifier\n",
        "    print('VGG19 모델 셋팅 완료')\n",
        "\n",
        "    # Training\n",
        "    import numpy as np\n",
        "    import cv2\n",
        "    import random\n",
        "    import time\n",
        "    import torch.optim as optim\n",
        "\n",
        "    from tqdm import tqdm # tqdm은 작업의 진행률을 시각적으로 표시해준다.\n",
        "\n",
        "    # train\n",
        "    def train_epoch(model, loader, device, criterion, optimizer):\n",
        "        model.train() # 모델 train 모드로 바꾸기\n",
        "        train_loss = []\n",
        "        bar = tqdm(loader)\n",
        "\n",
        "        for i, (data, target) in enumerate(bar):\n",
        "            optimizer.zero_grad() # 최적화된 모든 변수 초기화\n",
        "\n",
        "            data, target = data.to(device), target.to(device) # 지정한 device로 데이터 옮기기\n",
        "            logits = model(data) # 1. forward pass\n",
        "\n",
        "            loss = criterion(logits, target) # 2. loss계산\n",
        "            loss.backward() # 3. backward pass\n",
        "            optimizer.step() # 4. gradient descent(파라미터 업데이트)\n",
        "\n",
        "            loss_np = loss.detach().cpu().numpy() # loss값 가져오기 위해 gpu에 있던 데이터 모두 cpu로 옮기기\n",
        "            train_loss.append(loss_np)\n",
        "            bar.set_description('loss: %.5f' % (loss_np))\n",
        "\n",
        "        train_loss = np.mean(train_loss) # 한 epoch당 train loss의 평균 구하기\n",
        "        return train_loss\n",
        "\n",
        "    # Validation\n",
        "    def val_epoch(model, loader, device, criterion):\n",
        "        model.eval() # 모델 evaluate 모드로 바꾸기\n",
        "        val_loss = []\n",
        "        LOGITS = []\n",
        "        PROBS = []\n",
        "        TARGETS = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for (data, target) in tqdm(loader):\n",
        "\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                logits = model(data)    # 1. forward pass\n",
        "                probs = logits.softmax(1)\n",
        "\n",
        "                LOGITS.append(logits.detach().cpu())\n",
        "                PROBS.append(probs.detach().cpu())\n",
        "                TARGETS.append(target.detach().cpu())\n",
        "\n",
        "                loss = criterion(logits, target)    # 2. loss 계산\n",
        "                val_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "        val_loss = np.mean(val_loss)\n",
        "        LOGITS = torch.cat(LOGITS).numpy()\n",
        "        PROBS = torch.cat(PROBS).numpy()\n",
        "        TARGETS = torch.cat(TARGETS).numpy()\n",
        "\n",
        "        # accuracy: 정확도\n",
        "        acc = (PROBS.argmax(1) == TARGETS).mean() * 100.\n",
        "\n",
        "        return val_loss, acc\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    # 학습시키기\n",
        "    def run(model = model, init_lr = 4e-6, n_epochs = 15):\n",
        "        # gpu 사용\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"현재 장치: {device}\")\n",
        "        # model을 지정한 장치로 옮기기\n",
        "        model = model.to(device)\n",
        "\n",
        "        # loss function 지정\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # optimizer로 adam 사용\n",
        "        optimizer = optim.Adam(model.parameters(), lr = init_lr)\n",
        "\n",
        "        \n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        accurates = []\n",
        "        \n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "            print(time.ctime(), f'Epoch {epoch}')\n",
        "\n",
        "            train_loss = train_epoch(model, train_loader, device, criterion, optimizer) # train\n",
        "            val_loss, acc = val_epoch(model, valid_loader, device, criterion) # validation\n",
        "\n",
        "            content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {(val_loss):.5f}, Acc: {(acc):.4f}.'\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_losses)\n",
        "            accurates.append(acc)\n",
        "            print(content)\n",
        "        \n",
        "        return train_losses, val_losses, accurates\n",
        "        \n",
        "\n",
        "    train_losses, val_losses, accurates = run(model, init_lr=4e-6, n_epochs=epochNum)\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/FingerNumber_classifier_project/best_model.pth')\n",
        "    print(\"가장 좋은 성능의 모델 저장 완료!\")\n",
        "    print(\"학습 종료\");\n",
        "\n",
        "    plt.plot(range(1, epochNum+1), train_losses, 'r', label=\"train_loss\")\n",
        "    plt.plot(range(1, epochNum+1), val_losses, 'g', label=\"valid_loss\")\n",
        "    plt.plot(range(1, epochNum+1), accurates, 'b', label=\"accurate\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    print(\"\\n테스트셋으로 최종 정확도를 계산합니다.\")\n",
        "    \n",
        "    def test_epoch(model, loader, device, criterion):\n",
        "        model.eval() # 모델 evaluate 모드로 바꾸기\n",
        "        val_loss = []\n",
        "        LOGITS = []\n",
        "        PROBS = []\n",
        "        TARGETS = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for (data, target) in tqdm(loader):\n",
        "\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                logits = model(data)    # 1. forward pass\n",
        "                probs = logits.softmax(1)\n",
        "\n",
        "                LOGITS.append(logits.detach().cpu())\n",
        "                PROBS.append(probs.detach().cpu())\n",
        "                TARGETS.append(target.detach().cpu())\n",
        "\n",
        "                loss = criterion(logits, target)    # 2. loss 계산\n",
        "                val_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "        val_loss = np.mean(val_loss)\n",
        "        LOGITS = torch.cat(LOGITS).numpy()\n",
        "        PROBS = torch.cat(PROBS).numpy()\n",
        "        TARGETS = torch.cat(TARGETS).numpy()\n",
        "\n",
        "        # accuracy: 정확도\n",
        "        acc = (PROBS.argmax(1) == TARGETS).mean() * 100.\n",
        "\n",
        "        return val_loss, acc\n",
        "    \n",
        "    def run_test(model = model, init_lr = 4e-6, n_epochs = 1):\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        # loss function 지정\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # optimizer로 adam 사용\n",
        "        optimizer = optim.Adam(model.parameters(), lr = init_lr)\n",
        "\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "            test_loss, acc = test_epoch(model, test_loader, device, criterion) # test\n",
        "            print(f'\\t새로운 이미지에 대한 정확도: {acc}.')\n",
        "\n",
        "    run_test(model)\n",
        "\n",
        "\n",
        "elif menu == '1': # 새로운 이미지 분류\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/FingerNumber_classifier_project/best_model.pth'))\n",
        "    model.eval()\n",
        "    print(\"사진은 png확장자여야 합니다.\")\n",
        "    print(\"분류할 사진 파일을 /content/drive/MyDrive/FingerNumber_classifier_project 경로에 newImage.png 의 이름으로 추가해주시기 바랍니다.\")\n",
        "    print(\"새로운 사진은 어떤 숫자를 나타내는지 예측해봅니다.\")\n",
        "\n",
        "    newImage = Image.open(\"/content/drive/MyDrive/FingerNumber_classifier_project/newImage.png\").convert('RGB')\n",
        "    \n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FingerNumber_Classifier\n",
            "[0] 모델 새로 학습하기\n",
            "[1] 학습된 모델로 새로운 사진 분류해보기\n",
            "[any] 종료\n",
            "숫자를 입력해주세요: 0\n",
            "모델을 새로 학습합니다.\n",
            "15 에포크 기준 정확도는 약 79%입니다.\n",
            "원하는 에포크 수를 입력해주세요: 15\n",
            "15으로 에포크를 설정하였습니다.\n",
            "모델 학습을 시작합니다.\n",
            "csv파일 생성 완료!\n",
            "csv 파일 DataFrame으로 저장 완료!\n",
            "훈련셋, 검증셋, 테스트셋 분할 완료!\n",
            "훈련셋 개수:192, 검증셋 개수:48, 테스트셋 개수: 60\n",
            "rgb의 mean, std값 계산 완료!\n",
            "모델 트랜스폼 불러오기 완료!\n",
            "dataset class 객체 생성 완료!\n",
            "데이터 로더 완료!\n",
            "VGG19 모델 셋팅 완료\n",
            "현재 장치: cuda\n",
            "Fri Nov 26 12:05:05 2021 Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2.05362: 100%|██████████| 192/192 [00:10<00:00, 17.77it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:05:18 2021 Epoch 1, lr: 0.0000040, train loss: 2.36034, valid loss: 2.05616, Acc: 27.0833.\n",
            "Fri Nov 26 12:05:18 2021 Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2.78342: 100%|██████████| 192/192 [00:10<00:00, 17.89it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:05:31 2021 Epoch 2, lr: 0.0000040, train loss: 2.09223, valid loss: 1.83794, Acc: 45.8333.\n",
            "Fri Nov 26 12:05:31 2021 Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 1.86187: 100%|██████████| 192/192 [00:10<00:00, 17.83it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:05:44 2021 Epoch 3, lr: 0.0000040, train loss: 1.88765, valid loss: 1.54286, Acc: 45.8333.\n",
            "Fri Nov 26 12:05:44 2021 Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 1.49576: 100%|██████████| 192/192 [00:10<00:00, 17.61it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:05:57 2021 Epoch 4, lr: 0.0000040, train loss: 1.76718, valid loss: 1.32376, Acc: 64.5833.\n",
            "Fri Nov 26 12:05:57 2021 Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2.40531: 100%|██████████| 192/192 [00:10<00:00, 17.66it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:06:10 2021 Epoch 5, lr: 0.0000040, train loss: 1.61949, valid loss: 1.17482, Acc: 68.7500.\n",
            "Fri Nov 26 12:06:10 2021 Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2.16979: 100%|██████████| 192/192 [00:10<00:00, 17.69it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:06:23 2021 Epoch 6, lr: 0.0000040, train loss: 1.42935, valid loss: 0.99277, Acc: 77.0833.\n",
            "Fri Nov 26 12:06:23 2021 Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.45133: 100%|██████████| 192/192 [00:10<00:00, 17.68it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:06:37 2021 Epoch 7, lr: 0.0000040, train loss: 1.34545, valid loss: 0.88738, Acc: 81.2500.\n",
            "Fri Nov 26 12:06:37 2021 Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.62772: 100%|██████████| 192/192 [00:10<00:00, 17.68it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:06:50 2021 Epoch 8, lr: 0.0000040, train loss: 1.20355, valid loss: 0.76689, Acc: 83.3333.\n",
            "Fri Nov 26 12:06:50 2021 Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.17237: 100%|██████████| 192/192 [00:10<00:00, 17.70it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 21.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:07:03 2021 Epoch 9, lr: 0.0000040, train loss: 1.17671, valid loss: 0.70028, Acc: 89.5833.\n",
            "Fri Nov 26 12:07:03 2021 Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.08487: 100%|██████████| 192/192 [00:10<00:00, 17.76it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:07:16 2021 Epoch 10, lr: 0.0000040, train loss: 1.09611, valid loss: 0.60241, Acc: 85.4167.\n",
            "Fri Nov 26 12:07:16 2021 Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.49686: 100%|██████████| 192/192 [00:10<00:00, 17.65it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 21.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:07:29 2021 Epoch 11, lr: 0.0000040, train loss: 1.04675, valid loss: 0.58563, Acc: 87.5000.\n",
            "Fri Nov 26 12:07:29 2021 Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2.45193: 100%|██████████| 192/192 [00:10<00:00, 17.71it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:07:42 2021 Epoch 12, lr: 0.0000040, train loss: 0.92678, valid loss: 0.52368, Acc: 87.5000.\n",
            "Fri Nov 26 12:07:42 2021 Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.19769: 100%|██████████| 192/192 [00:10<00:00, 17.72it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:07:55 2021 Epoch 13, lr: 0.0000040, train loss: 1.00206, valid loss: 0.50811, Acc: 89.5833.\n",
            "Fri Nov 26 12:07:55 2021 Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2.39693: 100%|██████████| 192/192 [00:10<00:00, 17.65it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:08:08 2021 Epoch 14, lr: 0.0000040, train loss: 0.82540, valid loss: 0.41007, Acc: 93.7500.\n",
            "Fri Nov 26 12:08:08 2021 Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.65982: 100%|██████████| 192/192 [00:10<00:00, 17.73it/s]\n",
            "100%|██████████| 48/48 [00:02<00:00, 22.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:08:21 2021 Epoch 15, lr: 0.0000040, train loss: 0.93957, valid loss: 0.39805, Acc: 93.7500.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLDtq9yR2NVq",
        "outputId": "a7ad9b85-3e0c-426d-9ee5-eac4a32cecaa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}