{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FingerNumber_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WHbB-R3GlJiILResPx0i2Sx__A20q7N-",
      "authorship_tag": "ABX9TyNYq+AX8FpxTeB+TT8FmGFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongjiGo/FingerNumber_classifier/blob/master/FingerNumber_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "q8xXWfV86dgA",
        "outputId": "6b85e170-43c4-4e94-ecb4-961bc7093d4b"
      },
      "source": [
        "print(\"FingerNumber_Classifier\")\n",
        "print(\"[0] 모델 새로 학습하기\")\n",
        "print(\"[1] 학습된 모델로 새로운 사진 분류해보기\")\n",
        "print(\"[any] 종료\")\n",
        "\n",
        "\n",
        "menu = input(\"숫자를 입력해주세요: \")\n",
        "\n",
        "if menu == '0':\n",
        "    print(\"모델을 새로 학습합니다.\")\n",
        "    print(\"15 에포크 기준 정확도는 약 79%입니다.\")\n",
        "    epochNum = int(input(\"원하는 에포크 수를 입력해주세요: \"))\n",
        "    print(f\"{epochNum}으로 에포크를 설정하였습니다.\")\n",
        "    print(\"모델 학습을 시작합니다.\")\n",
        "\n",
        "elif menu == '1':\n",
        "    print(\"분류를 진행합니다.\")\n",
        "    file_path = input(\"파일의 [절대경로]를 입력해주세요: \")\n",
        "\n",
        "else:\n",
        "    print('프로그램을 종료합니다.')\n",
        "\n",
        "if menu == '0':\n",
        "    # 데이터 셋 구성하기, 경로를 파악한 후\n",
        "    # 클래스 이름(name), 클래스(class), 그리고 학습을 위한 클래스를 숫자로 나타낸 타겟(target)을 csv파일에 저장\n",
        "    import os\n",
        "    from glob import glob # 인자로 받은 패턴과 이름이 일치하는 모든 파일과 디렉터리의 리스트 반환\n",
        "    import pandas as pd\n",
        "\n",
        "    file_path = './drive/MyDrive/FingerNumber_classifier_project/dataSet/*/*.png' # 데이터의 경로 저장\n",
        "    file_list = glob(file_path)\n",
        "\n",
        "    data_dict = {'image_name':[], 'class':[], 'target':[], 'file_path':[]}\n",
        "    # 학습에 사용하기 위한 넘버링(?)\n",
        "    target_dict = {'yi_1': 0, 'er_2': 1, 'san_3': 2, 'si_4':3, 'wu_5':4, 'liu_6':5, 'qi_7':6, 'ba_8':7, 'jiu_9':8, 'shi_10': 9}\n",
        "\n",
        "    for path in file_list:\n",
        "        data_dict['file_path'].append(path) # file_path 항목에 파일 경로 저장\n",
        "\n",
        "        path_list = path.split(os.path.sep) # os별 파일 경로 구분 문자로 split\n",
        "\n",
        "        data_dict['image_name'].append(path_list[-1]) # 이미지 이름 저장\n",
        "        data_dict['class'].append(path_list[-2]) # 어떤 클래스인지 저장\n",
        "        data_dict['target'].append(target_dict[path_list[-2]]) # 그 클래스의 번호 저장\n",
        "\n",
        "    train_df = pd.DataFrame(data_dict) # 데이터 프레임 화\n",
        "    train_df.to_csv(\"./drive/MyDrive/FingerNumber_classifier_project/train.csv\", mode='w') # csv파일로 생성\n",
        "    print('csv파일 생성 완료!')\n",
        "\n",
        "    from sklearn.model_selection import train_test_split # 스플릿 모듈\n",
        "    def get_df():\n",
        "        # csv 파일 읽어서 DataFrame으로 저장\n",
        "        df = pd.read_csv(\"./drive/MyDrive/FingerNumber_classifier_project/train.csv\") # csv로 불러와서 데이터 저장\n",
        "        print('csv 파일 DataFrame으로 저장 완료!')\n",
        "\n",
        "        # 데이터셋을 train, val, test로 나누기\n",
        "        df_train, df_test = train_test_split(df, test_size=0.2)\n",
        "        df_train, df_val = train_test_split(df_train, test_size=0.2)\n",
        "        print('훈련셋, 검증셋, 테스트셋 분할 완료!')\n",
        "        return df_train, df_val, df_test\n",
        "\n",
        "    # 데이터셋 읽어오기\n",
        "    df_train, df_val, df_test = get_df()\n",
        "    print(f'훈련셋 개수:{len(df_train)}, 검증셋 개수:{len(df_val)}, 테스트셋 개수: {len(df_test)}') # 192, 48, 60\n",
        "\n",
        "    import torch\n",
        "    from torch.utils.data import Dataset\n",
        "    from PIL import Image\n",
        "\n",
        "    # 학습시, 데이터셋을 사용할 수 있도록 만들기\n",
        "    class Classification_Dataset(Dataset):\n",
        "        def __init__(self, csv, mode, transform=None):\n",
        "            self.csv = csv.reset_index(drop=True) # random으로 섞인 데이터의 인덱스를 reset 시켜서 다시 부여한다.\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return self.csv.shape[0] # csv 파일의 행 개수 == 데이터 개수\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            row = self.csv.iloc[index] # 주어진 index에 대한 데이터 뽑아오기\n",
        "            image = Image.open(row.file_path).convert('RGB') # 파일 경로로 부터 이미지를 읽고 rgb로 변환하기\n",
        "            target = torch.tensor(self.csv.iloc[index].target).long()\n",
        "\n",
        "            if self.transform:\n",
        "                image = self.transform(image) # 이미지에 transform 적용하기\n",
        "\n",
        "            return image, target # 이미지와 target return하기기\n",
        "\n",
        "\n",
        "    # normalize를 위해 rgb 채널의 mean, std 값 구하기\n",
        "\n",
        "    import numpy as np\n",
        "    from torchvision import transforms\n",
        "    dataset_train = Classification_Dataset(df_train, 'train', transform=transforms.ToTensor())\n",
        "\n",
        "    # 데이터(shape:torch.Size([3, 381, 343])) rgb에 대한 mean, std 구하기\n",
        "    rgb_mean = [np.mean(x.numpy(), axis=(1, 2)) for x, _ in dataset_train]\n",
        "    rgb_std = [np.std(x.numpy(), axis=(1, 2)) for x, _ in dataset_train]\n",
        "\n",
        "    # 각 데이터 채널별로 mean, std 나타내기\n",
        "    c_mean = []\n",
        "    c_std = []\n",
        "    for i in range(3):\n",
        "        c_mean.append(np.mean([m[i] for m in rgb_mean]))\n",
        "        c_std.append(np.std([s[i] for s in rgb_std]))\n",
        "\n",
        "    print('rgb의 mean, std값 계산 완료!')\n",
        "    # 사용자 모델 트랜스폼\n",
        "    def get_transforms(image_size):\n",
        "        transforms_train = transforms.Compose([\n",
        "            transforms.RandomRotation(30), # 이미지의 다양화를 위해 랜덤으로 +- 30도 가량 회전\n",
        "            transforms.RandomResizedCrop(image_size), # 이미지 사이즈 축소\n",
        "            transforms.RandomHorizontalFlip(), # 이미지를 랜덤으로 수평하게 뒤집음.\n",
        "            transforms.ToTensor(), # 데이터 타입을 텐서로 변경\n",
        "            transforms.Normalize(c_mean, c_std) ]) # 정규화\n",
        "\n",
        "        transforms_val = transforms.Compose([transforms.Resize(image_size + 30), # 이미지 사이즈 축소\n",
        "                                             transforms.CenterCrop(image_size), # 이미지의 가운데 부분을 인자값으로 자름\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize(c_mean, c_std)])\n",
        "        \n",
        "        transforms_test = transforms.Compose([transforms.Resize(image_size),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize(c_mean, c_std)]) # 정규화\n",
        "\n",
        "        return transforms_train, transforms_val, transforms_test\n",
        "\n",
        "    # 모델 트랜스폼 가져오기\n",
        "    transforms_train, transforms_val, transforms_test = get_transforms(224)\n",
        "    print(\"모델 트랜스폼 불러오기 완료!\")\n",
        "\n",
        "    # dataset class 객체 만들기\n",
        "    dataset_train = Classification_Dataset(df_train, 'train', transform=transforms_train)\n",
        "    dataset_val = Classification_Dataset(df_val, 'valid', transform=transforms_val)\n",
        "    dataset_test = Classification_Dataset(df_test, 'test', transform=transforms_test) \n",
        "    print('dataset class 객체 생성 완료!')\n",
        "\n",
        "    # DataLoader는 Classification_Dataset으로 받아온 데이터(이미지, target)를 batch로 묶어 return합니다.\n",
        "    from torch.utils.data.sampler import RandomSampler\n",
        "    from torch.utils.data import DataLoader\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=1, sampler=RandomSampler(dataset_train), num_workers=0)\n",
        "    valid_loader = torch.utils.data.DataLoader(dataset_val, batch_size=1, num_workers=0)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1, num_workers=0)\n",
        "    print('데이터 로더 완료!')\n",
        "    #### 데이터 준비 파트는 마무리가 되었습니다. 큰 틀을 살펴보면서 정리해보도록 하겠습니다.\n",
        "    # 0. 데이터셋 다운받기`: 여러분이 수집한 데이터의 클래스별로 폴더를 구성하여 데이터셋을 준비합니다.\n",
        "    # 1. 데이터셋 구성하기`: 저장한 데이터의 정보를 csv 파일로 만듭니다.\n",
        "    # 2. 데이터셋 불러오기`: csv 파일을 통해 데이터를 불러와서 train, validation, test로 나눠줍니다.\n",
        "    # 3. 학습 시, 데이터셋을 사용할 수 있도록 만들기\n",
        "    #     3-1. Dataset Class`: pytorch가 dataset을 어떻게 읽을지 알려주는 클래스를 만듭니다. (데이터셋 크기와 지정한 인덱스별로 데이터를 리턴해주는 len, getitem 함수가 포함되어 있습니다.)\n",
        "    #     3-2. Transforms & Augmentation`: 학습을 위해 데이터를 가공합니다.\n",
        "    #     3-3. Data Loaders`: 배치별로 데이터를 묶어줍니다. Training시, 배치단위별로 데이터가 호출됩니다.\n",
        "\n",
        "    # Model 설정\n",
        "    from torchvision import models\n",
        "    from collections import OrderedDict\n",
        "    import torch.nn as nn\n",
        "\n",
        "    model = models.vgg19(pretrained=True)\n",
        "    # # Backprop을 수행하지 않도록 parameter들을 동결시키기\n",
        "    # # 재학습을 위해, 모든 parameters의 gradient를 꺼놓기\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 마지막 layer를 과제에 맞게 수정하기\n",
        "    classifier = nn.Sequential(OrderedDict([\n",
        "        ('fc1', nn.Linear(25088, 500)),\n",
        "        ('relu', nn.ReLU()),\n",
        "        ('fc2', nn.Linear(500, 10))\n",
        "    ]))\n",
        "\n",
        "    model.classifier = classifier\n",
        "    print('VGG19 모델 셋팅 완료')\n",
        "\n",
        "    # Training\n",
        "    import numpy as np\n",
        "    import cv2\n",
        "    import random\n",
        "    import time\n",
        "    import torch.optim as optim\n",
        "\n",
        "    from tqdm import tqdm # tqdm은 작업의 진행률을 시각적으로 표시해준다.\n",
        "\n",
        "    # train\n",
        "    def train_epoch(model, loader, device, criterion, optimizer):\n",
        "        model.train() # 모델 train 모드로 바꾸기\n",
        "        train_loss = []\n",
        "        bar = tqdm(loader)\n",
        "\n",
        "        for i, (data, target) in enumerate(bar):\n",
        "            optimizer.zero_grad() # 최적화된 모든 변수 초기화\n",
        "\n",
        "            data, target = data.to(device), target.to(device) # 지정한 device로 데이터 옮기기\n",
        "            logits = model(data) # 1. forward pass\n",
        "\n",
        "            loss = criterion(logits, target) # 2. loss계산\n",
        "            loss.backward() # 3. backward pass\n",
        "            optimizer.step() # 4. gradient descent(파라미터 업데이트)\n",
        "\n",
        "            loss_np = loss.detach().cpu().numpy() # loss값 가져오기 위해 gpu에 있던 데이터 모두 cpu로 옮기기\n",
        "            train_loss.append(loss_np)\n",
        "            bar.set_description('loss: %.5f' % (loss_np))\n",
        "\n",
        "        train_loss = np.mean(train_loss) # 한 epoch당 train loss의 평균 구하기\n",
        "        return train_loss\n",
        "\n",
        "    # Validation\n",
        "    def val_epoch(model, loader, device, criterion):\n",
        "        model.eval() # 모델 evaluate 모드로 바꾸기\n",
        "        val_loss = []\n",
        "        LOGITS = []\n",
        "        PROBS = []\n",
        "        TARGETS = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for (data, target) in tqdm(loader):\n",
        "\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                logits = model(data)    # 1. forward pass\n",
        "                probs = logits.softmax(1)\n",
        "\n",
        "                LOGITS.append(logits.detach().cpu())\n",
        "                PROBS.append(probs.detach().cpu())\n",
        "                TARGETS.append(target.detach().cpu())\n",
        "\n",
        "                loss = criterion(logits, target)    # 2. loss 계산\n",
        "                val_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "        val_loss = np.mean(val_loss)\n",
        "        LOGITS = torch.cat(LOGITS).numpy()\n",
        "        PROBS = torch.cat(PROBS).numpy()\n",
        "        TARGETS = torch.cat(TARGETS).numpy()\n",
        "\n",
        "        # accuracy: 정확도\n",
        "        acc = (PROBS.argmax(1) == TARGETS).mean() * 100.\n",
        "\n",
        "        return val_loss, acc\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    # 학습시키기\n",
        "    def run(model = model, init_lr = 4e-6, n_epochs = 15):\n",
        "        # gpu 사용\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"현재 장치: {device}\")\n",
        "        # model을 지정한 장치로 옮기기\n",
        "        model = model.to(device)\n",
        "\n",
        "        # loss function 지정\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # optimizer로 adam 사용\n",
        "        optimizer = optim.Adam(model.parameters(), lr = init_lr)\n",
        "\n",
        "        \n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        accurates = []\n",
        "        \n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "            print(time.ctime(), f'Epoch {epoch}')\n",
        "\n",
        "            train_loss = train_epoch(model, train_loader, device, criterion, optimizer) # train\n",
        "            val_loss, acc = val_epoch(model, valid_loader, device, criterion) # validation\n",
        "\n",
        "            content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {(val_loss):.5f}, Acc: {(acc):.4f}.'\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            accurates.append(acc)\n",
        "            print(content)\n",
        "        \n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/FingerNumber_classifier_project/best_model.pth')\n",
        "        return train_losses, val_losses, accurates\n",
        "        \n",
        "\n",
        "    train_losses, val_losses, accurates = run(model, init_lr=4e-6, n_epochs=epochNum)\n",
        "    print(\"가장 좋은 성능의 모델 저장 완료!\")\n",
        "    print(\"학습 종료\");\n",
        "\n",
        "    plt.plot(range(1, epochNum+1), train_losses, 'r', label=\"train_loss\")\n",
        "    plt.plot(range(1, epochNum+1), val_losses, 'g', label=\"valid_loss\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(range(1, epochNum+1), accurates, 'b', label=\"accurate\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accurate')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n테스트셋으로 최종 정확도를 계산합니다.\")\n",
        "    \n",
        "    def test_epoch(model, loader, device, criterion):\n",
        "        model.eval() # 모델 evaluate 모드로 바꾸기\n",
        "        val_loss = []\n",
        "        LOGITS = []\n",
        "        PROBS = []\n",
        "        TARGETS = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for (data, target) in tqdm(loader):\n",
        "\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                logits = model(data)    # 1. forward pass\n",
        "                probs = logits.softmax(1)\n",
        "\n",
        "                LOGITS.append(logits.detach().cpu())\n",
        "                PROBS.append(probs.detach().cpu())\n",
        "                TARGETS.append(target.detach().cpu())\n",
        "\n",
        "                loss = criterion(logits, target)    # 2. loss 계산\n",
        "                val_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "        val_loss = np.mean(val_loss)\n",
        "        LOGITS = torch.cat(LOGITS).numpy()\n",
        "        PROBS = torch.cat(PROBS).numpy()\n",
        "        TARGETS = torch.cat(TARGETS).numpy()\n",
        "\n",
        "        # accuracy: 정확도\n",
        "        acc = (PROBS.argmax(1) == TARGETS).mean() * 100.\n",
        "\n",
        "        return val_loss, acc\n",
        "    \n",
        "    def run_test(model = model, init_lr = 4e-6, n_epochs = 1):\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        # loss function 지정\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # optimizer로 adam 사용\n",
        "        optimizer = optim.Adam(model.parameters(), lr = init_lr)\n",
        "\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "            test_loss, acc = test_epoch(model, test_loader, device, criterion) # test\n",
        "            print(f'\\t새로운 이미지에 대한 정확도: {acc}.')\n",
        "\n",
        "    run_test(model)\n",
        "\n",
        "\n",
        "elif menu == '1': # 새로운 이미지 분류\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/FingerNumber_classifier_project/best_model.pth'))\n",
        "    model.eval()\n",
        "    print(\"사진은 png확장자여야 합니다.\")\n",
        "    print(\"분류할 사진 파일을 /content/drive/MyDrive/FingerNumber_classifier_project 경로에 newImage.png 의 이름으로 추가해주시기 바랍니다.\")\n",
        "    print(\"새로운 사진은 어떤 숫자를 나타내는지 예측해봅니다.\")\n",
        "\n",
        "    newImage = Image.open(\"/content/drive/MyDrive/FingerNumber_classifier_project/newImage.png\").convert('RGB')\n",
        "    \n",
        "    \n",
        "    \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FingerNumber_Classifier\n",
            "[0] 모델 새로 학습하기\n",
            "[1] 학습된 모델로 새로운 사진 분류해보기\n",
            "[any] 종료\n",
            "숫자를 입력해주세요: 0\n",
            "모델을 새로 학습합니다.\n",
            "15 에포크 기준 정확도는 약 79%입니다.\n",
            "원하는 에포크 수를 입력해주세요: 100\n",
            "100으로 에포크를 설정하였습니다.\n",
            "모델 학습을 시작합니다.\n",
            "csv파일 생성 완료!\n",
            "csv 파일 DataFrame으로 저장 완료!\n",
            "훈련셋, 검증셋, 테스트셋 분할 완료!\n",
            "훈련셋 개수:192, 검증셋 개수:48, 테스트셋 개수: 60\n",
            "rgb의 mean, std값 계산 완료!\n",
            "모델 트랜스폼 불러오기 완료!\n",
            "dataset class 객체 생성 완료!\n",
            "데이터 로더 완료!\n",
            "VGG19 모델 셋팅 완료\n",
            "현재 장치: cuda\n",
            "Fri Nov 26 12:41:25 2021 Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2.31063: 100%|██████████| 96/96 [00:09<00:00, 10.57it/s]\n",
            "100%|██████████| 24/24 [00:01<00:00, 12.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:41:36 2021 Epoch 1, lr: 0.0000040, train loss: 2.34561, valid loss: 2.23968, Acc: 20.8333.\n",
            "Fri Nov 26 12:41:36 2021 Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 1.89346: 100%|██████████| 96/96 [00:08<00:00, 10.71it/s]\n",
            "100%|██████████| 24/24 [00:01<00:00, 12.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 12:41:47 2021 Epoch 2, lr: 0.0000040, train loss: 2.14044, valid loss: 2.03733, Acc: 39.5833.\n",
            "Fri Nov 26 12:41:47 2021 Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2.15426:  73%|███████▎  | 70/96 [00:06<00:02, 10.67it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f9bfa927e3c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccurates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"가장 좋은 성능의 모델 저장 완료!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"학습 종료\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-f9bfa927e3c2>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model, init_lr, n_epochs)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Epoch {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-f9bfa927e3c2>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, device, criterion, optimizer)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 최적화된 모든 변수 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_t\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_print_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmininterval\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcur_t\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_start_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_print_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m                         \u001b[0mlast_print_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_print_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m                         \u001b[0mlast_print_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_print_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ema_dn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ema_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_miniters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                     \u001b[0;31m# If no `miniters` was specified, adjust automatically to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mprint_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mfp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mfp_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mlast_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLDtq9yR2NVq",
        "outputId": "60791906-271e-4ecb-837f-d8ae3c16a482"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}